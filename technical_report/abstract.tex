\begin{abstract}

恶意评论分类能够自动判别一段评论文本是否带有恶意倾向，有助于社区管理员维护互联网社区环境。由于恶意评论中往往会提及一些敏感身份词，例如``黑人''、``同性恋''等等，模型在学习对评论进行分类的时候往往会错误地将身份词与恶意评论建立因果关系，因此需要去偏方法消除模型学习过程中产生的这种偏见。本文使用BERT模型，结合基于信息论方法的去偏算法解决恶意评论分类问题。该方法通过建立概率图模型消除神经网络推理中的环境因素。模型在测试集上达到了93.41\%的准确率。模型实现代码公布在：\url{https://github.com/hiyouga/Toxic_Detection}。

\end{abstract}
