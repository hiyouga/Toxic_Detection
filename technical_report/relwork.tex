\section{技术调研} % 丁雨宽

\subsection{恶意评论分类}

为了保护社交媒体中的用户免受网络恶意评论的骚扰，近年来，许多基于不同模型的恶意评论系统被提出，用于自动检测互联网社区中的恶意评论。Gaydhani\cite{gaydhani2018detecting}等人利用支持向量机检测推特上的恶意评论。Bojkovsky和Pikuliak\cite{bojkovsky2019stufiit}基于对抗学习提出用于恶意评论分类的双向长短期记忆（Bi-LSTM）模型。d'Sa\cite{d2020bert}等人使用fastText嵌入和BERT嵌入作为CNN和Bi-LSTM分类器的输入特征，并对预训练的BERT模型进行微调。

\subsection{深度学习去偏}

最初版本的恶意评论分类器对某些语句有明显错误分类的趋势，例如含有某些身份术语的明显无恶意的陈述，``我是一个同性恋''，该类句子被赋予了不合理的高恶意评分，肤色、性别、种族、人口、残疾、宗教信仰等，或者这些因素的复杂组合会极大的影响分类的正确率。

部分研究者试图通过处理训练数据集来消除偏见。例如，Dixon\cite{dixon2018measuring}等人通过添加包含敏感词汇的非恶意评论来平衡数据集。Park\cite{park2018reducing}等人结合去偏词嵌入和性别互换数据来减少恶意评论分类任务中的性别偏见。Badjatiya\cite{badjatiya2019stereotypical}等人在训练集中采用了基于多重知识统一化的替换偏差敏感词的策略。

另一些研究者更注重模型的修改和无偏特征的学习。Xia\cite{xia2020demoting}等人使用对抗训练来减少模型将敏感文本误分类为恶意评论的倾向。Mozafari\cite{mozafari2020hate}等人提出了一种新的加权机制，以减少英语推文中的种族偏见。Vaidya\cite{vaidya2020empirical}等人(2020)应用了一个带有注意层的多任务学习框架，以防止模型学习特定触发词和恶意标签之间的错误关联。

Chang\cite{chang2020invariant}等人借助博弈论框架来施加不变性，将IRM原理扩展到神经预测，并进一步提出了不变解释（InvRat），一种纳入不变约束的解释模型。Chuang\cite{chuang2021mitigating}等人在不变解释模型的基础上，排除输入文本中与恶意标签高度但虚假相关的句法和语义模式，并在推理过程中掩盖这些部分。

本文在先前工作的基础上，通过结合BERT和不变解释模型，基于信息论方法的去偏算法解决恶意评论分类问题。
